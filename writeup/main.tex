\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\setcounter{secnumdepth}{0}
\usepackage[margin=1in]{geometry}
\title{COMP551 Assignment 1: Analysis and Discussion}

\author{Thomas Lewis, Gabe Woloz, Vivek Motta}
\date{February 2026}

\begin{document}

\maketitle

% Abstract (100–250 words) Summarize the task, methodology, and key findings.
\begin{abstract}
    In this project, we analyze the Capitol Bike Sharing dataset and implement and train a linear regression model on the data in order to predict the total count (i.e. number of rentals) based on environmental data. We cleaned and processed our data to better fit our model and then, using the closed form equation for linear regression, we created the model and trained it. We finally applied feature engineering techniques such as polynomial, log, interactions and sine cosine transformations on the features and compared the resulting data. We found that essentially all of our feature engineering resulting in better performance of the model (lower MSE) compared to the unchanged data.
\end{abstract}

\section{Introduction}
% Introduction (5+ sentences) Describe the dataset, the modeling approach, and the goals of the project.
The dataset used for this project captures the daily and hourly usage of a bike sharing program in Washington D.C. between 2011 and 2012. It contains environmental information in the area as well as the number of bikes being rented at the time. This project aims to train a simple linear regression model on this data to accurately predict the rental count based on the other features such as current weather conditions and date.

\section{Data Preprocessing and Exploration}
% Data Preprocessing and Exploration (5+ sentences) Explain cleaning, transformations, and visualization.
\subsection{Handling missing values}
As the dataset's website stated, there were no missing values in the data. We confirmed this with Pandas.
\subsection{Cleaning}
We dropped the `casual' and `registered' features as their sum is equal to the target, `cnt'. This prevents these features from leaking the target when training.
\subsection{Scaling and encoding choices}
We encoded weather and season with one-hot as they are categorical, non-ordinal features. We chose not to scale any features as the histograms we generated for the continuous features showed no significant skew or scaling issues (see figure \ref{plots}).
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{plots.png}
    \caption{Data Visualization Plots}
    \label{plots}
\end{figure}
\subsection{Effect on numerical stability}
Numerical stability should decrease with one-hot encoding since more columns/features are being considered with the risk of collinearity.

\section{Methods}
% Describe your linear regression implementation and feature engineering approach.
\subsection{Linear Regression Implementation}
We used the closed form equation discussed in the lecture to implement our linear regression model, where instead of inverting the matrix, least squares (pseudo inverse) was used to keep numerical stability.
\[
w^*=(X^\top X)^{-1}X^\top y \to X^{\dagger}y
\]
\subsection{Transformations evaluated}

We evaluated polynomial, log, interaction, and sine cosine transformations. Each choice was guided by patterns we observed directly in the data. In particular, squared (polynomial) features were added for the continuous environmental variables ('temp', 'atemp', 'hum', 'windspeed') because the scatter plots showed clear curved relationships with rental counts rather than straight lines. As shown in Figure 2 "Temperature vs Count with quadratic fit", temperature follows an inverted-U trend, where rentals peak at moderate temperatures and drop off at both low and high extremes. The quadratic fit highlights this non-linear behavior that a simple linear term cannot capture. Including squared terms allows linear regression to better approximate these curved trends.

We applied a log transformation to 'hum' to compress its scale and check whether changes in lower humidity levels (for example, 20\% to 40\%) have a larger impact than similar changes at higher levels (60\% to 80\%), suggesting a proportional rather than additive effect.

Interaction terms were also created between environmental pairs ('temp' × 'hum', 'temp' × 'windspeed') to model combined effects. Figure 2 "Temp–Humidity interaction colored by count" shows why this is useful. Rental demand depends on specific combinations of temperature and humidity, not just either variable on its own. For example, high temperatures may feel comfortable in low humidity but uncomfortable in high humidity.
Finally, sine and cosine transformations were applied to cyclical time features ('mnth', 'weekday', 'hr') to reflect their periodic structure. Figure 2 "Average rentals by month (seasonal pattern)" demonstrates this seasonal behavior. Without cyclical encoding, the model treats hour 23 and hour 0 as far apart even though they are consecutive in time, which makes it harder to capture patterns like commute peaks or the transition from December to January.

\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{writeup/Graphs.png}
    \caption{Data Visualization Plots Extended}
    \label{plots}
\end{figure}

\section{Results}
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{cols.png}
    \includegraphics[width=1\linewidth]{MSEData2.png}
    \caption{MSE data}
    \label{results}
\end{figure}
% Report quantitative results (MSE) and include figures or tables where appropriate.
\subsection{Effect of feature engineering on model performance}

Most engineered features reduced the model's mean squared error, although the improvements varied. The largest gains came from the polynomial (squared) features ('temp','atemp','hum','windspeed'). These variables showed stronger curved relationships with "cnt" compared to the other engineered features. As seen in Figure 2 "Temperature vs Count with quadratic fit", rentals clearly peak at moderate temperatures, and the quadratic fit captures this inverted-U pattern that a linear model alone would miss. This explains why squared terms led to a noticeable drop in MSE. 

The interaction terms ('temp' $\times$ 'hum', 'temp' $\times$ 'windspeed') produced moderate MSE improvements, especially for the hourly dataset (Figure 3). Figure 2 "Temp--Humidity interaction colored by count" illustrates how these features work together to influence demand. High rental counts occur in specific temperature-humidity combinations rather than being determined by either variable independently. Their smaller gains compared to polynomial features indicate that while interactions matter, the primary non-linearity is captured by squared terms.

The log transformation of humidity gave mixed results. While it slightly reduced MSE in some cases, it also increased the condition number, introducing multicollinearity without much predictive value. This suggests humidity's relationship with rentals is not logarithmic. 

The sine cosine features ('month', 'weekday', 'hr') had a strong effect on hourly data but increased MSE for daily data. This difference comes from how cyclical patterns appear in each dataset. For hourly data, these transformations reduced MSE by capturing diurnal patterns and the continuity between hour 23 and hour 0. For daily data, Figure 2 "Average rentals by month (seasonal pattern)" shows more discrete seasonal regimes rather than smooth sinusoidal cycles. This reflects the assumption that months and weekdays have a purely cyclical effect on "cnt", while in practice specific months and weekends, which are better captured with one-hot encoding, have a larger effect. Hours in a day, however, follow a clear cycle and strongly affect total count. This shows feature engineering should match the data generation process, using cyclical encoding for truly periodic patterns and categorical encoding for distinct regimes.


\subsection{Numerical stability of the model}
The numerical stability of the model is considered moderately conditioned (between $10^2$ and $10^6$)\textsuperscript{1} Each feature that was add increased the condition number, which decreased the numerical stability. The log transformation made the most significant difference in numerical stability, multiplying it five to ten times. This result can be explained by the feature selected ("hum"), which has no visible log relation to the target feature "cnt". This points to its weight probably being close to zero, which would increase the condition number and decrease numerical stability. \\
It is also important to note the lower condition number of the hour data. This is attributed to the higher sample to feature ratio which reduces the impact of localized multicollinearity.\\
\textsuperscript{1}https://www.cs.usask.ca/~spiteri/CMPT898/notes/numericalStability.pdf
\section{Discussion and Conclusion}
% Interpret results, discuss limitations, and suggest next steps.
\subsection{Signs of overfitting or capacity change}
Overfitting was measured with the ratio between the training and testing MSEs. Sine cosine transformations either reduced overfitting or kept it stable while others only increased it. This can be seen in the table in figure \ref{results}.
\subsection{Practical improvements and further experiments}
We could possibly experiment with creating new features with either of the strategies used in this experiment. Others, such as scaling, also have to potential to affect MSE even though very little skew was observed in the data. Finally, we could explore more advanced strategies such as regularization and observe it's effects on numerical stability and MSE.

\section{Statement of Contributions}
% Briefly describe how all team members contributed (1-3 sentences).
Thomas worked on tasks 2 and 3 and contributing to both the data preprocessing and the writeup document. Gabe worked on preprocessing and encoding as well as formatting data and creating plots for the data visualization section. Vivek worked on the writeup and verified what was done on other tasks.\\

\section{Statement on the Use of LLMs}
LLMs were used to debug code (find and explain errors in code) and to help interpret data that (Ex. Adding a feature leading to significantly worse numerical stability).

\end{document}

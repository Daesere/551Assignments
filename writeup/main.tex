\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\setcounter{secnumdepth}{0}
\usepackage[margin=1in]{geometry}
\title{COMP551 Assignment 1: Analysis and Discussion}

\author{Thomas Lewis, Gabe Woloz, Vivek Motta}
\date{February 2026}

\begin{document}

\maketitle

\section{Abstract}
% Abstract (100â€“250 words) Summarize the task, methodology, and key findings.
\begin{abstract}
    
\end{abstract}

\section{Introduction}
% Introduction (5+ sentences) Describe the dataset, the modeling approach, and the goals of the project.
The dataset used for this project captures the daily and hourly usage of a bike sharing program in Washington D.C. between 2011 and 2012. It contains environmental information in the area as well as the number of bikes being rented at the time. This project aims to train a simple linear regression model on this data to accurately predict the rental count based on the other features such as current weather conditions and date.

\section{Data Preprocessing and Exploration}
% Data Preprocessing and Exploration (5+ sentences) Explain cleaning, transformations, and visualization.
\subsection{Handling missing values}
As the dataset's website stated, there were no missing values in the data. We confirmed this with Pandas.
\subsection{Cleaning}
We dropped the `casual' and `registered' features as their sum is equal to the target, `cnt'. This prevents these features from leaking the target when training.
\subsection{Scaling and encoding choices}
We encoded weather and season with one-hot as they are categorical, non-ordinal features. We chose not to scale any features as the histograms we generated for the continuous features showed no significant skew or scaling issues.
\subsection{Effect on numerical stability}
Numerical stability should decrease with one-hot encoding since more columns/features are being considered with the risk of collinearity.

\section{Methods}
% Describe your linear regression implementation and feature engineering approach.
\subsection{Linear Regression Implementation}
\subsection{Transformations evaluated}
Polynomials, logs, interactions and sin cosine transformations were evaluated. (Explain why each and on what features, also add graphs showing the relation between each feature and count or the interaction between two features. This can be done by taking the prediction yh of count of each engineered feature)

\section{Results}
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{cols.png}
    \includegraphics[width=1\linewidth]{MSEData2.png}
    \caption{MSE data}
    \label{fig:placeholder}
\end{figure}
% Report quantitative results (MSE) and include figures or tables where appropriate.
\subsection{Effect of preprocessing on model performance}
Preprocessing consistently led to better performance across all features, which can be seen in Fig 1. (maybe say more?)
\subsection{Effect of feature engineering on model performance}
Almost every feature decreased the mean squared error of the model in different amounts. The features that caused the most significant change were the polynomial (squared) features ('temp','atemp','hum','windspeed'). This is attributed to the stronger polynomial correlation between these features and "cnt" than for the other engineered features. \\
The sin cosine features ('month', 'weekday', 'hr') had a string effect on the hourly data, while increased MSE in the daily data. This is due to the naive assumption that months in a year and days in a week had a cyclical effect on "cnt", while weekends, which can be better accounted for with one-hot encoding, have a greater effect. However, the cycle of hours in a day has a significant effect on the total count. (potentially explain the effect of others more in detail)
\subsection{Numerical stability of the model}
The numerical stability of the model is considered moderately conditioned (between $10^2$ and $10^6$)\textsuperscript{1} Each feature that was add increased the condition number, which decreased the numerical stability. The log transformation made the most significant difference in numerical stability, multiplying it five to ten times. This result can be explained by the feature selected ("hum"), which has no visible log relation to the target feature "cnt". This points to its weight probably being close to zero, which would increase the condition number and decrease numerical stability. \\
It is also important to note the lower condition number of the hour data. This is attributed to the higher sample to feature ratio which reduces the impact of localized multicollinearity.\\
\textsuperscript{1}https://www.cs.usask.ca/~spiteri/CMPT898/notes/numericalStability.pdf
\section{Discussion and Conclusion}
% Interpret results, discuss limitations, and suggest next steps.
\subsection{Signs of overfitting or capacity change}
Overfitting was measured with the ratio between the training and testing MSEs. Sin cosine transformations either reduced overfitting or kept it stable while others only increased it. This can be seen in the table in Fig 1.
\subsection{Bias vs variance considerations}
\subsection{External/unobserved factors and data limits}
\subsection{Practical improvements and further experiments}

\section{Statement of Contributions}
% Briefly describe how all team members contributed (1-3 sentences).
Thomas mostly worked on the Google Colab, completing parts 1 to 3 and contributing to 

\section{Statement on the Use of LLMs}
LLMs were used to debug code (find and explain errors in code) and to help interpret data that (Ex. Adding a feature leading to significantly worse numerical stability).

\end{document}
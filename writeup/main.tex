\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\setcounter{secnumdepth}{0}
\usepackage[margin=1in]{geometry}
\title{COMP551 Assignment 1: Analysis and Discussion}

\author{Thomas Lewis, Gabe Woloz, Vivek Motta}
\date{February 2026}

\begin{document}

\maketitle

% Abstract (100â€“250 words) Summarize the task, methodology, and key findings.
\begin{abstract}
    In this project, we analyze the Capitol Bike Sharing dataset and implement and train a linear regression model on the data in order to predict the total count (i.e. number of rentals) based on environmental data. We cleaned and processed our data to better fit our model and then, using the closed form equation for linear regression, we created the model and trained it. We finally applied feature engineering techniques such as polynomial, log, interactions and sine cosine transformations on the features and compared the resulting data. We found that essentially all of our feature engineering resulting in better performance of the model (lower MSE) compared to the unchanged data.
\end{abstract}

\section{Introduction}
% Introduction (5+ sentences) Describe the dataset, the modeling approach, and the goals of the project.
The dataset used for this project captures the daily and hourly usage of a bike sharing program in Washington D.C. between 2011 and 2012. It contains environmental information in the area as well as the number of bikes being rented at the time. This project aims to train a simple linear regression model on this data to accurately predict the rental count based on the other features such as current weather conditions and date.

\section{Data Preprocessing and Exploration}
% Data Preprocessing and Exploration (5+ sentences) Explain cleaning, transformations, and visualization.
\subsection{Handling missing values}
As the dataset's website stated, there were no missing values in the data. We confirmed this with Pandas.
\subsection{Cleaning}
We dropped the `casual' and `registered' features as their sum is equal to the target, `cnt'. This prevents these features from leaking the target when training.
\subsection{Scaling and encoding choices}
We encoded weather and season with one-hot as they are categorical, non-ordinal features. We chose not to scale any features as the histograms we generated for the continuous features showed no significant skew or scaling issues (see figure \ref{plots}).
\begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{plots.png}
    \caption{Data Visualization Plots}
    \label{plots}
\end{figure}
\subsection{Effect on numerical stability}
Numerical stability should decrease with one-hot encoding since more columns/features are being considered with the risk of collinearity.

\section{Methods}
% Describe your linear regression implementation and feature engineering approach.
\subsection{Linear Regression Implementation}
We used the closed form equation discussed in the lecture to implement our linear regression model, where instead of inverting the matrix, least squares (pseudo inverse) was used to keep numerical stability.
\[
w^*=(X^\top X)^{-1}X^\top y \to X^{\dagger}y
\]
\subsection{Transformations evaluated}
Polynomials, logs, interactions and sine cosine transformations were evaluated. (Explain why each and on what features, also add graphs showing the relation between each feature and count or the interaction between two features. This can be done by taking the prediction yh of count of each engineered feature)

\section{Results}
\begin{figure}[h]
    \centering
    \includegraphics[width=1\linewidth]{cols.png}
    \includegraphics[width=1\linewidth]{MSEData2.png}
    \caption{MSE data}
    \label{results}
\end{figure}
% Report quantitative results (MSE) and include figures or tables where appropriate.
\subsection{Effect of preprocessing on model performance}
Preprocessing consistently led to better performance across all features, which can be seen in figure \ref{results}. This is consistent with our expectations.
\subsection{Effect of feature engineering on model performance}
Almost every feature decreased the mean squared error of the model in different amounts. The features that caused the most significant change were the polynomial (squared) features ('temp','atemp','hum','windspeed'). This is attributed to the stronger polynomial correlation between these features and "cnt" than for the other engineered features. \\
The sine cosine features ('month', 'weekday', 'hr') had a string effect on the hourly data, while increased MSE in the daily data. This is due to the naive assumption that months in a year and days in a week had a cyclical effect on "cnt", while specific months and weekends, which can be better accounted for with one-hot encoding, have a greater effect. However, the cycle of hours in a day has a significant effect on the total count. (potentially explain the effect of others more in detail)
\subsection{Numerical stability of the model}
The numerical stability of the model is considered moderately conditioned (between $10^2$ and $10^6$)\textsuperscript{1} Each feature that was add increased the condition number, which decreased the numerical stability. The log transformation made the most significant difference in numerical stability, multiplying it five to ten times. This result can be explained by the feature selected ("hum"), which has no visible log relation to the target feature "cnt". This points to its weight probably being close to zero, which would increase the condition number and decrease numerical stability. \\
It is also important to note the lower condition number of the hour data. This is attributed to the higher sample to feature ratio which reduces the impact of localized multicollinearity.\\
\textsuperscript{1}https://www.cs.usask.ca/~spiteri/CMPT898/notes/numericalStability.pdf
\section{Discussion and Conclusion}
% Interpret results, discuss limitations, and suggest next steps.
\subsection{Signs of overfitting or capacity change}
Overfitting was measured with the ratio between the training and testing MSEs. Sine cosine transformations either reduced overfitting or kept it stable while others only increased it. This can be seen in the table in figure \ref{results}.
\subsection{Practical improvements and further experiments}
We could possibly experiment with creating new features with either of the strategies used in this experiment. Others, such as scaling, also have to potential to affect MSE even though very little skew was observed in the data. Finally, we could explore more advanced strategies such as regularization and observe it's effects on numerical stability and MSE.

\section{Statement of Contributions}
% Briefly describe how all team members contributed (1-3 sentences).
Thomas worked on tasks 2 and 3 and contributing to both the data preprocessing and the writeup document. Gabe worked on preprocessing and encoding as well as formatting data and creating plots for the data visualization section. Vivek worked on the writeup and verified what was done on other tasks.\\

\section{Statement on the Use of LLMs}
LLMs were used to debug code (find and explain errors in code) and to help interpret data that (Ex. Adding a feature leading to significantly worse numerical stability).

\end{document}
